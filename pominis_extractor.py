#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
import time
import re
from urllib.parse import urljoin, urlparse
from typing import List, Dict, Any, Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PominisExtractor:
    """Pominis.com promptæå–å™¨"""
    
    def __init__(self):
        self.base_url = "https://pominis.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://pominis.com/en'
        })
        self.stories = []
        
    def discover_api_endpoints(self) -> List[str]:
        """å‘ç°å¯èƒ½çš„APIç«¯ç‚¹"""
        potential_endpoints = [
            "/api/stories",
            "/api/stories/public",
            "/api/content/stories", 
            "/api/v1/stories",
            "/stories",
            "/content/stories",
            "/en/api/stories",
            "/_next/static/chunks/pages/",
            "/api/prompts",
            "/api/templates"
        ]
        
        working_endpoints = []
        for endpoint in potential_endpoints:
            url = urljoin(self.base_url, endpoint)
            try:
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    logger.info(f"å‘ç°å·¥ä½œçš„ç«¯ç‚¹: {url}")
                    working_endpoints.append(url)
                elif response.status_code in [401, 403]:
                    logger.info(f"éœ€è¦è®¤è¯çš„ç«¯ç‚¹: {url}")
                    working_endpoints.append(url)
            except Exception as e:
                logger.debug(f"ç«¯ç‚¹ {url} ä¸å¯ç”¨: {e}")
                
        return working_endpoints
    
    def extract_from_html(self, url: str = None) -> Dict[str, Any]:
        """ä»HTMLé¡µé¢æå–æ•…äº‹æ•°æ®"""
        if not url:
            url = f"{self.base_url}/en"
            
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            html_content = response.text
            
            # æŸ¥æ‰¾Next.jsæ•°æ®
            patterns = [
                r'__NEXT_DATA__"[^>]*>([^<]+)',
                r'window\.__NEXT_DATA__\s*=\s*([^;]+)',
                r'"props":\s*({[^}]+})',
                r'"stories":\s*(\[[^\]]+\])',
                r'"pageProps":\s*({.+?})'
            ]
            
            extracted_data = {}
            for pattern in patterns:
                matches = re.findall(pattern, html_content, re.DOTALL)
                if matches:
                    for match in matches:
                        try:
                            data = json.loads(match)
                            extracted_data[f"pattern_{pattern[:20]}"] = data
                            logger.info(f"æ‰¾åˆ°æ•°æ®: {pattern[:20]}")
                        except json.JSONDecodeError:
                            continue
                            
            return extracted_data
            
        except Exception as e:
            logger.error(f"HTMLæå–å¤±è´¥: {e}")
            return {}
    
    def check_network_requests(self) -> List[str]:
        """æ£€æŸ¥å¯èƒ½çš„ç½‘ç»œè¯·æ±‚æ¨¡å¼"""
        # åˆ†æç½‘ç«™å¯èƒ½å‘é€çš„è¯·æ±‚
        common_patterns = [
            "/api/stories?page=1&limit=20",
            "/api/stories?sort=latest",
            "/api/stories?sort=popular", 
            "/api/stories?genre=Fantasy",
            "/api/content/public",
            "/api/stories/featured",
            "/_next/data/build-id/en.json",
            "/_next/data/build-id/en/stories.json"
        ]
        
        results = []
        for pattern in common_patterns:
            url = urljoin(self.base_url, pattern)
            try:
                response = self.session.get(url, timeout=5)
                if response.status_code == 200:
                    logger.info(f"æœ‰æ•ˆè¯·æ±‚: {url}")
                    results.append(url)
                    
                    # å°è¯•è§£æJSON
                    try:
                        data = response.json()
                        if isinstance(data, dict) and ('stories' in data or 'data' in data):
                            logger.info(f"æ‰¾åˆ°æ•…äº‹æ•°æ®: {len(data.get('stories', data.get('data', [])))}")
                    except:
                        pass
                        
            except Exception as e:
                logger.debug(f"è¯·æ±‚å¤±è´¥ {url}: {e}")
                
        return results
    
    def extract_story_details(self, story_id: str) -> Dict[str, Any]:
        """æå–å•ä¸ªæ•…äº‹çš„è¯¦ç»†ä¿¡æ¯"""
        story_urls = [
            f"/api/stories/{story_id}",
            f"/en/story/{story_id}",
            f"/story/{story_id}",
            f"/api/content/{story_id}"
        ]
        
        for story_url in story_urls:
            url = urljoin(self.base_url, story_url)
            try:
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    if 'application/json' in response.headers.get('content-type', ''):
                        return response.json()
                    else:
                        # ä»HTMLæå–
                        html = response.text
                        # æŸ¥æ‰¾æ•…äº‹å†…å®¹çš„pattern
                        story_patterns = [
                            r'"story":\s*({[^}]+})',
                            r'"content":\s*"([^"]+)"',
                            r'"prompt":\s*"([^"]+)"',
                            r'"description":\s*"([^"]+)"'
                        ]
                        
                        story_data = {}
                        for pattern in story_patterns:
                            matches = re.findall(pattern, html)
                            if matches:
                                story_data[pattern[:10]] = matches
                                
                        return story_data
                        
            except Exception as e:
                logger.debug(f"æ•…äº‹è¯¦æƒ…æå–å¤±è´¥ {url}: {e}")
                
        return {}
    
    def search_stories_by_genre(self, genre: str = "Fantasy") -> List[Dict]:
        """æŒ‰ç±»å‹æœç´¢æ•…äº‹"""
        search_urls = [
            f"/api/stories?genre={genre}",
            f"/api/search?q={genre}",
            f"/en/genre/{genre}",
            f"/stories?filter={genre}"
        ]
        
        all_stories = []
        for search_url in search_urls:
            url = urljoin(self.base_url, search_url)
            try:
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    if 'application/json' in response.headers.get('content-type', ''):
                        data = response.json()
                        if isinstance(data, dict):
                            stories = data.get('stories', data.get('data', []))
                            all_stories.extend(stories)
                        elif isinstance(data, list):
                            all_stories.extend(data)
                            
                        logger.info(f"ä» {url} æ‰¾åˆ° {len(stories if 'stories' in locals() else data)} ä¸ªæ•…äº‹")
                        
            except Exception as e:
                logger.debug(f"æœç´¢å¤±è´¥ {url}: {e}")
                
        return all_stories
    
    def extract_all_prompts(self) -> Dict[str, Any]:
        """æå–æ‰€æœ‰å¯ç”¨çš„prompt"""
        logger.info("å¼€å§‹æå–Pominisæ‰€æœ‰prompt...")
        
        results = {
            'stories': [],
            'prompts': [],
            'api_endpoints': [],
            'extraction_methods': []
        }
        
        # 1. å‘ç°APIç«¯ç‚¹
        logger.info("æ­¥éª¤1: å‘ç°APIç«¯ç‚¹...")
        endpoints = self.discover_api_endpoints()
        results['api_endpoints'] = endpoints
        
        # 2. ä»HTMLé¡µé¢æå–
        logger.info("æ­¥éª¤2: ä»HTMLæå–æ•°æ®...")
        html_data = self.extract_from_html()
        if html_data:
            results['html_extraction'] = html_data
            results['extraction_methods'].append('html_parsing')
        
        # 3. æ£€æŸ¥ç½‘ç»œè¯·æ±‚
        logger.info("æ­¥éª¤3: æ£€æŸ¥ç½‘ç»œè¯·æ±‚...")
        network_requests = self.check_network_requests() 
        results['network_requests'] = network_requests
        
        # 4. æŒ‰ç±»å‹æœç´¢
        logger.info("æ­¥éª¤4: æŒ‰ç±»å‹æœç´¢æ•…äº‹...")
        genres = ['Fantasy', 'Horror', 'Science Fiction', 'Mystery', 'Romance', 'Drama']
        for genre in genres:
            stories = self.search_stories_by_genre(genre)
            if stories:
                results['stories'].extend(stories)
                results['extraction_methods'].append(f'genre_search_{genre}')
        
        # 5. æå–æ•…äº‹è¯¦æƒ…
        logger.info("æ­¥éª¤5: æå–æ•…äº‹è¯¦æƒ…...")
        story_ids = self._extract_story_ids_from_results(results)
        for story_id in story_ids[:10]:  # é™åˆ¶ä¸ºå‰10ä¸ª
            details = self.extract_story_details(story_id)
            if details:
                results['story_details'] = results.get('story_details', [])
                results['story_details'].append({'id': story_id, 'details': details})
        
        # 6. æ±‡æ€»ç»Ÿè®¡
        results['summary'] = {
            'total_stories_found': len(results['stories']),
            'working_endpoints': len(results['api_endpoints']),
            'extraction_methods_used': len(results['extraction_methods']),
            'story_details_extracted': len(results.get('story_details', []))
        }
        
        logger.info(f"æå–å®Œæˆ! æ‰¾åˆ° {results['summary']['total_stories_found']} ä¸ªæ•…äº‹")
        return results
    
    def _extract_story_ids_from_results(self, results: Dict) -> List[str]:
        """ä»ç»“æœä¸­æå–æ•…äº‹ID"""
        story_ids = []
        
        # ä»storiesä¸­æå–ID
        for story in results.get('stories', []):
            if isinstance(story, dict):
                story_id = story.get('id') or story.get('_id') or story.get('storyId')
                if story_id:
                    story_ids.append(str(story_id))
        
        # ä»HTMLæ•°æ®ä¸­æå–ID
        html_data = results.get('html_extraction', {})
        for key, data in html_data.items():
            if isinstance(data, dict):
                if 'stories' in data and isinstance(data['stories'], list):
                    for story in data['stories']:
                        if isinstance(story, dict):
                            story_id = story.get('id') or story.get('_id')
                            if story_id:
                                story_ids.append(str(story_id))
        
        return list(set(story_ids))  # å»é‡
    
    def save_results(self, results: Dict[str, Any], filename: str = "pominis_extraction_results.json"):
        """ä¿å­˜æå–ç»“æœ"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    extractor = PominisExtractor()
    
    print("ğŸ” Pominis Prompt æå–å™¨")
    print("=" * 50)
    
    # æå–æ‰€æœ‰prompt
    results = extractor.extract_all_prompts()
    
    # æ˜¾ç¤ºæ‘˜è¦
    summary = results['summary']
    print(f"\nğŸ“Š æå–æ‘˜è¦:")
    print(f"  æ‰¾åˆ°æ•…äº‹æ•°é‡: {summary['total_stories_found']}")
    print(f"  å¯ç”¨APIç«¯ç‚¹: {summary['working_endpoints']}")
    print(f"  ä½¿ç”¨çš„æå–æ–¹æ³•: {summary['extraction_methods_used']}")
    print(f"  æå–çš„æ•…äº‹è¯¦æƒ…: {summary['story_details_extracted']}")
    
    # ä¿å­˜ç»“æœ
    extractor.save_results(results)
    
    # æ˜¾ç¤ºéƒ¨åˆ†æå–çš„å†…å®¹
    if results['stories']:
        print(f"\nğŸ“š æ‰¾åˆ°çš„æ•…äº‹ç¤ºä¾‹:")
        for i, story in enumerate(results['stories'][:3]):
            print(f"  {i+1}. {story.get('title', 'Unknown Title')}")
            if story.get('description'):
                print(f"     æè¿°: {story['description'][:100]}...")
    
    if results['api_endpoints']:
        print(f"\nğŸ”— å‘ç°çš„APIç«¯ç‚¹:")
        for endpoint in results['api_endpoints'][:5]:
            print(f"  - {endpoint}")
    
    print(f"\nâœ… å®Œæˆ! è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° pominis_extraction_results.json")

if __name__ == "__main__":
    main()