from typing import Dict, Any, Optional
import asyncio
from datetime import datetime

from reasoning_graph import Stage1ReasoningGraph
from info_extractor import create_info_extractor


class AgentService:
    def __init__(self, model_name: str = "gpt-4o-mini"):
        """åˆå§‹åŒ–AgentæœåŠ¡ - å•ç”¨æˆ·ç‰ˆæœ¬"""
        self.model_name = model_name

        # å•ä¸€ä¼šè¯å®ä¾‹
        self.reasoning_graph: Optional[Stage1ReasoningGraph] = None

        # ä¿¡æ¯æå–å™¨
        self.extractor = create_info_extractor(model_name)

        print(f"AgentServiceåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")

    def start_conversation(self) -> Dict[str, Any]:
        """å¼€å§‹å¯¹è¯ä¼šè¯"""
        # åˆ›å»ºæ–°çš„Stage1æ¨ç†å›¾å®ä¾‹
        self.reasoning_graph = Stage1ReasoningGraph(self.model_name, self.extractor)

        welcome_message = """ğŸ® æ‚¨å¥½ï¼æˆ‘æ˜¯æ•™è‚²æ¸¸æˆè®¾è®¡åŠ©æ‰‹ï¼

æˆ‘å°†é€šè¿‡å‡ ä¸ªç®€å•çš„é—®é¢˜æ¥äº†è§£æ‚¨çš„éœ€æ±‚ï¼Œç„¶åä¸ºæ‚¨ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„RPGæ•™è‚²æ¸¸æˆè®¾è®¡æ–¹æ¡ˆã€‚

è®©æˆ‘ä»¬å¼€å§‹å§ï¼è¯·å‘Šè¯‰æˆ‘ï¼š
- è¿™ä¸ªæ¸¸æˆæ˜¯ç»™å“ªä¸ªå¹´çº§çš„å­¦ç”Ÿè®¾è®¡çš„ï¼Ÿ
- ä¸»è¦æƒ³æ•™æˆå“ªä¸ªå­¦ç§‘çš„å†…å®¹ï¼Ÿ
- æœ‰ç‰¹å®šçš„çŸ¥è¯†ç‚¹éœ€è¦é‡ç‚¹å…³æ³¨å—ï¼Ÿ

æ‚¨å¯ä»¥ä¸€æ¬¡å›ç­”æ‰€æœ‰é—®é¢˜ï¼Œä¹Ÿå¯ä»¥é€ä¸€å›ç­” ğŸ˜Š"""

        return {
            "message": welcome_message,
            "status": "session_started",
            "timestamp": self._get_timestamp(),
            "next_action": "await_user_input"
        }

    async def process_request(self, user_input: str) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘"""

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
        if self.reasoning_graph is None:
            return {
                "error": "ä¼šè¯æœªå¼€å§‹ï¼Œè¯·å…ˆå¼€å§‹å¯¹è¯",
                "action": "start_session",
                "timestamp": self._get_timestamp()
            }

        try:
            # æ ¸å¿ƒå¤„ç†ï¼šè°ƒç”¨æ¨ç†å›¾å¤„ç†å¯¹è¯è½®æ¬¡
            result = await self.reasoning_graph.process_conversation_turn(user_input)

            # æ·»åŠ metadataå­—æ®µ
            result["ready_for_stage2"] = (result["next_action"] == "proceed_to_stage2")

            # æ ¹æ®æ¨ç†å›¾çš„ç»“æœå†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ
            if result["next_action"] == "proceed_to_stage2":
                # Stage1å®Œæˆï¼Œä½†ä»ä½¿ç”¨collectionæ ¼å¼è¿”å›
                return self._format_collection_response(result)

            elif result["next_action"] == "continue_collection":
                # Stage1æœªå®Œæˆï¼Œç»§ç»­æ”¶é›†ä¿¡æ¯
                return self._format_collection_response(result)

            else:
                # å¤„ç†å…¶ä»–å¯èƒ½çš„çŠ¶æ€
                return self._format_general_response(result)

        except Exception as e:
            print(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}")
            return {
                "error": f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "action": "retry",
                "timestamp": self._get_timestamp()
            }

    async def _transition_to_stage2(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """è¿‡æ¸¡åˆ°Stage2 - ç”Ÿæˆæ¸¸æˆå†…å®¹"""
        requirements = result["requirements"]

        # TODO: è¿™é‡Œå°†æ¥è°ƒç”¨Stage2å’ŒStage3çš„é€»è¾‘
        # stage2_result = await self.stage2_service.generate_story_blueprint(requirements)
        # stage3_result = await self.stage3_service.generate_scenes(stage2_result)

        # æ¸…ç†Stage1ä¼šè¯
        self.reasoning_graph = None

        return {
            "response": result["response"] + "\n\nğŸš€ éœ€æ±‚æ”¶é›†å®Œæˆï¼æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆæ¸¸æˆå†…å®¹ï¼Œè¯·ç¨å€™...",
            "stage": "stage1_complete",
            "next_stage": "stage2_generation",
            "requirements": requirements,
            "timestamp": self._get_timestamp(),
            "action": "generate_content"
        }

    def _format_collection_response(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–Stage1ä¿¡æ¯æ”¶é›†ä¸­çš„å“åº”"""
        response_data = {
            "response": result["response"],
            "ready_for_stage2": result.get("ready_for_stage2", False),
            "timestamp": self._get_timestamp(),
        }
        
        # å¦‚æœStage1å®Œæˆï¼Œè¿”å›å®ŒæˆçŠ¶æ€çš„ä¿¡æ¯
        if result.get("next_action") == "proceed_to_stage2":
            response_data.update({
                "stage": "stage1_complete",
                "requirement_id": result.get("requirement_id"),
                "requirements": result.get("requirements"),
                "action": "stage1_completed"
            })
        else:
            # Stage1æœªå®Œæˆï¼Œè¿”å›æ”¶é›†çŠ¶æ€çš„ä¿¡æ¯
            response_data.update({
                "stage": "stage1_collecting", 
                "current_stage": result["lacked_info"]["stage"],
                "missing_fields": result["lacked_info"]["missing_fields"],
                "completion_rate": result["lacked_info"]["completion_rate"],
                "action": "continue_conversation"
            })
            
        return response_data

    def _format_general_response(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ä¸€èˆ¬å“åº”"""
        return {
            "response": result.get("response", "æˆ‘ç†è§£äº†æ‚¨çš„è¾“å…¥ï¼Œè¯·ç»§ç»­..."),
            "stage": result.get("stage", "unknown"),
            "timestamp": self._get_timestamp(),
            "action": "continue_conversation"
        }

    def get_session_status(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯çŠ¶æ€"""
        if self.reasoning_graph is None:
            return {
                "status": "no_session",
                "message": "ä¼šè¯æœªå¼€å§‹",
                "timestamp": self._get_timestamp()
            }

        current_stage = self.reasoning_graph.determine_current_stage()

        if current_stage == "complete":
            completion_rate = 1.0
            missing_fields = []
        else:
            lacked_info = self.reasoning_graph.get_lacked_info()
            completion_rate = lacked_info["completion_rate"]
            missing_fields = lacked_info["missing_fields"]

        return {
            "status": "active",
            "current_stage": current_stage,
            "completion_rate": completion_rate,
            "missing_fields": missing_fields,
            "collected_info": self.reasoning_graph.collected_info,
            "timestamp": self._get_timestamp()
        }

    def end_session(self) -> Dict[str, Any]:
        """ç»“æŸä¼šè¯"""
        if self.reasoning_graph is None:
            return {
                "status": "no_session",
                "message": "ä¼šè¯ä¸å­˜åœ¨",
                "timestamp": self._get_timestamp()
            }

        # è·å–æœ€ç»ˆæ”¶é›†çš„ä¿¡æ¯
        final_info = self.reasoning_graph.collected_info

        # æ¸…ç†ä¼šè¯
        self.reasoning_graph = None

        return {
            "status": "session_ended",
            "message": "ä¼šè¯å·²æˆåŠŸç»“æŸ",
            "final_collected_info": final_info,
            "timestamp": self._get_timestamp()
        }

    def reset_session(self) -> Dict[str, Any]:
        """é‡ç½®ä¼šè¯"""
        # é‡æ–°åˆ›å»ºæ¨ç†å›¾å®ä¾‹
        self.reasoning_graph = Stage1ReasoningGraph(self.model_name, self.extractor)

        return {
            "status": "session_reset",
            "message": "ä¼šè¯å·²é‡ç½®ï¼Œè®©æˆ‘ä»¬é‡æ–°å¼€å§‹",
            "timestamp": self._get_timestamp()
        }

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# ä¾¿åˆ©å‡½æ•°
def create_agent_service(model_name: str = "gpt-4o-mini") -> AgentService:
    """åˆ›å»ºAgentæœåŠ¡çš„ä¾¿åˆ©å‡½æ•°"""
    return AgentService(model_name)


# æ¼”ç¤ºå‡½æ•°
async def demo_conversation():
    """æ¼”ç¤ºå®Œæ•´çš„å¯¹è¯æµç¨‹"""
    agent = create_agent_service()

    print("=== æ•™è‚²æ¸¸æˆè®¾è®¡åŠ©æ‰‹æ¼”ç¤º ===")

    # å¼€å§‹ä¼šè¯
    start_result = agent.start_conversation()
    print(f"åŠ©æ‰‹: {start_result['message']}")

    # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥
    test_inputs = [
        "æˆ‘æƒ³ä¸ºä¸‰å¹´çº§å­¦ç”Ÿåšä¸€ä¸ªæ•°å­¦æ¸¸æˆ",
        "é‡ç‚¹æ˜¯10ä»¥å†…çš„åŠ æ³•ï¼Œå¾ˆå¤šå­¦ç”Ÿå®¹æ˜“ç®—é”™",
        ""
    ]

    for i, user_input in enumerate(test_inputs, 1):
        print(f"\nç¬¬{i}è½®å¯¹è¯:")
        print(f"ç”¨æˆ·: {user_input}")

        result = await agent.process_request(user_input)
        print(f"åŠ©æ‰‹: {result['response']}")

        if result.get("action") == "generate_content":
            print("\nğŸ‰ Stage1å®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆæ¸¸æˆå†…å®¹ï¼")
            print(f"æ”¶é›†åˆ°çš„éœ€æ±‚: {result['requirements']}")
            break

        # æ˜¾ç¤ºå½“å‰è¿›åº¦
        if "completion_rate" in result:
            progress = result["completion_rate"] * 100
            print(f"è¿›åº¦: {progress:.1f}%")


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(demo_conversation())