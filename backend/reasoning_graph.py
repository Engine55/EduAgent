from langchain.chains import ConversationChain
from langchain.memory import ConversationSummaryBufferMemory  
from langchain_openai import ChatOpenAI
from typing import Dict, List, TypedDict, Any
import json
import hashlib
from datetime import datetime
from langgraph.graph import StateGraph, END
import os

from database_client import db_client


# ==================== StateGraphç‰ˆæœ¬çš„ReasoningGraph ====================

class ReasoningState(TypedDict):
    """ReasoningGraphçš„çŠ¶æ€å®šä¹‰ - åŒ…å«Stage1åˆå¹¶çš„å­—æ®µ"""
    # åŸºç¡€ä¼šè¯çŠ¶æ€
    session_id: str
    messages: List[Dict[str, str]]
    user_id: str
    
    # éœ€æ±‚æ”¶é›†çŠ¶æ€
    collected_info: Dict[str, Any]
    stage1_complete: bool
    
    # === ä»ŽStage1ä¿ç•™çš„çŠ¶æ€å­—æ®µ ===
    extracted_info: Dict[str, Any]  # å½“å‰è½®æå–çš„ä¿¡æ¯
    current_stage: str              # å½“å‰æ‰€åœ¨é˜¶æ®µ
    
    # è¯¦ç»†åº¦è¯„ä¼°çŠ¶æ€
    sufficiency_score: Dict[str, float]  # å„ç»´åº¦sufficiencyè¯„åˆ†
    overall_sufficiency: float           # æ€»ä½“sufficiencyè¯„åˆ†
    sufficiency_threshold: float         # é˜ˆå€¼ (é»˜è®¤75)
    sufficiency_passed: bool
    
    # é€‚å®œæ€§æ£€æŸ¥çŠ¶æ€
    fitness_assessment: Dict[str, Any]
    fitness_concerns: List[Dict[str, str]]
    fitness_passed: bool
    
    # æœ€ç»ˆçŠ¶æ€
    ready_for_generation: bool
    final_requirements: Dict[str, Any]


class ReasoningGraph:
    """åŸºäºŽStateGraphçš„æ™ºèƒ½æŽ¨ç†å›¾ - åˆå¹¶äº†Stage1åŠŸèƒ½"""
    
    def __init__(self, db_client=None):
        self.db_client = db_client or db_client
        
        # åˆå§‹åŒ–LLM
        import os
        from dotenv import load_dotenv
        load_dotenv()
        
        self.llm = ChatOpenAI(
            model="gpt-4o-mini", 
            temperature=0.7,  # å¯¹è¯ç”Ÿæˆä½¿ç”¨è¾ƒé«˜æ¸©åº¦
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # åˆå§‹åŒ–ä¿¡æ¯æå–å™¨
        from info_extractor import create_info_extractor
        self.extractor = create_info_extractor("gpt-4o-mini")
        
        # ===== ä»ŽStage1ReasoningGraphåˆå¹¶çš„çŠ¶æ€ç®¡ç† =====
        
        # åˆå§‹åŒ–Memory (ä»ŽStage1åˆå¹¶)
        self.memory = ConversationSummaryBufferMemory(
            max_token_limit=8000,
            llm=self.llm,
            return_messages=True
        )
        
        # æ”¶é›†çš„ä¿¡æ¯å­˜å‚¨ (ä»ŽStage1åˆå¹¶)
        self.collected_info = {
            "subject": None,
            "grade": None,
            "knowledge_points": None,
            "teaching_goals": None,
            "teaching_difficulties": None,
            "game_style": None,
            "character_design": None,
            "world_setting": None,
            "plot_requirements": None,
            "interaction_requirements": None
        }
        
        # å®Œæˆæ¡ä»¶å®šä¹‰ (ä»ŽStage1åˆå¹¶)
        self.completion_criteria = {
            "basic_info": ["subject", "grade", "knowledge_points"],
            "teaching_info": ["teaching_goals", "teaching_difficulties"],
            "gamestyle_info": ["game_style", "character_design", "world_setting"],
            "scene_info": ["plot_requirements", "interaction_requirements"]
        }
        
        # å¯¼å…¥promptæ¨¡æ¿ (ä»ŽStage1åˆå¹¶)
        from prompt_templates import PromptTemplates
        self.prompts = PromptTemplates()
        
        self.graph = self._build_reasoning_graph()
    
    # ===== ä»ŽStage1ReasoningGraphåˆå¹¶çš„æ–¹æ³• =====
    
    def determine_current_stage(self) -> str:
        """ç¡®å®šå½“å‰åº”è¯¥æ”¶é›†å“ªä¸ªé˜¶æ®µçš„ä¿¡æ¯"""
        if not self._stage_completed("basic_info"):
            return "basic_info"
        elif not self._stage_completed("teaching_info"):
            return "teaching_info"
        elif not self._stage_completed("gamestyle_info"):
            return "gamestyle_info"
        elif not self._stage_completed("scene_info"):
            return "scene_info"
        else:
            return "complete"

    def _stage_completed(self, stage: str) -> bool:
        """æ£€æŸ¥ç‰¹å®šé˜¶æ®µæ˜¯å¦å®Œæˆ"""
        required_fields = self.completion_criteria[stage]
        for field in required_fields:
            value = self.collected_info.get(field)
            if not value:
                return False
            if isinstance(value, list) and len(value) == 0:
                return False
        return True
        
    async def extract_info(self, user_input: str, stage: str = "basic_info") -> Dict:
        """æå–ç”¨æˆ·è¾“å…¥ä¸­çš„ä¿¡æ¯"""
        return await self.extractor.extract_from_user_input(user_input, stage)

    def update_state(self, extracted_info: Dict) -> None:
        """æ›´æ–°æ”¶é›†çŠ¶æ€"""
        print(f"DEBUG update_state: received = {extracted_info}")
        for key, value in extracted_info.items():
            print(f"DEBUG: processing key={key}, value={value}")
            if value and key in self.collected_info:
                if isinstance(value, list):
                    # å¤„ç†åˆ—è¡¨ç±»åž‹çš„æ•°æ®
                    if self.collected_info[key]:
                        # åˆå¹¶åˆ—è¡¨ï¼ŒåŽ»é‡
                        existing = self.collected_info[key] if isinstance(self.collected_info[key], list) else [self.collected_info[key]]
                        combined = existing + value
                        self.collected_info[key] = list(set(combined))
                    else:
                        self.collected_info[key] = value
                else:
                    # å¤„ç†å­—ç¬¦ä¸²ç±»åž‹çš„æ•°æ®
                    self.collected_info[key] = value
        
        print(f"DEBUG update_state: final collected_info = {self.collected_info}")

    def check_stage_completion(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¾¾æˆStage1ç›®æ ‡"""
        return self.determine_current_stage() == "complete"
    
    def get_lacked_info(self) -> Dict:
        """èŽ·å–ç¼ºå¤±ä¿¡æ¯è¯¦æƒ…"""
        current_stage = self.determine_current_stage()

        if current_stage == "complete":
            return {"stage": "complete", "missing_fields": [], "missing_details": {}, "completion_rate": 1.0}
        
        print(f"current stage is {current_stage}")
        # æ ¹æ®å½“å‰é˜¶æ®µèŽ·å–ç¼ºå¤±ä¿¡æ¯
        if current_stage == "basic_info":
            return self._check_basic_info_gaps()
        elif current_stage == "teaching_info":
            return self._check_teaching_info_gaps()
        elif current_stage == "gamestyle_info":
            return self._check_gamestyle_info_gaps()
        elif current_stage == "scene_info":
            return self._check_scene_info_gaps()
        else:
            return {"stage": current_stage, "missing_fields": [], "missing_details": {}, "completion_rate": 0.0}

    def _check_basic_info_gaps(self) -> Dict:
        """æ£€æŸ¥åŸºç¡€ä¿¡æ¯ç¼ºå¤±"""
        missing_fields = []
        missing_details = {}
        
        if not self.collected_info.get("subject"):
            missing_fields.append("subject")
            missing_details["subject"] = "å­¦ç§‘é¢†åŸŸ"
        if not self.collected_info.get("grade"):
            missing_fields.append("grade")
            missing_details["grade"] = "ç›®æ ‡å¹´çº§"
        if not self.collected_info.get("knowledge_points"):
            missing_fields.append("knowledge_points")
            missing_details["knowledge_points"] = "å…·ä½“çŸ¥è¯†ç‚¹"
        
        completion_rate = 1.0 - len(missing_fields) / 3
        return {
            "stage": "basic_info",
            "missing_fields": missing_fields,
            "missing_details": missing_details,
            "completion_rate": completion_rate
        }

    def _check_teaching_info_gaps(self) -> Dict:
        """æ£€æŸ¥æ•™å­¦ä¿¡æ¯ç¼ºå¤±"""
        missing_fields = []
        missing_details = {}
        
        if not self.collected_info.get("teaching_goals"):
            missing_fields.append("teaching_goals")
            missing_details["teaching_goals"] = "æ•™å­¦ç›®æ ‡"
        if not self.collected_info.get("teaching_difficulties"):
            missing_fields.append("teaching_difficulties")
            missing_details["teaching_difficulties"] = "æ•™å­¦éš¾ç‚¹"
        
        completion_rate = 1.0 - len(missing_fields) / 2
        return {
            "stage": "teaching_info",
            "missing_fields": missing_fields,
            "missing_details": missing_details,
            "completion_rate": completion_rate
        }

    def _check_gamestyle_info_gaps(self) -> Dict:
        """æ£€æŸ¥æ¸¸æˆé£Žæ ¼ä¿¡æ¯ç¼ºå¤±"""
        missing_fields = []
        missing_details = {}
        
        if not self.collected_info.get("game_style"):
            missing_fields.append("game_style")
            missing_details["game_style"] = "æ¸¸æˆé£Žæ ¼"
        if not self.collected_info.get("character_design"):
            missing_fields.append("character_design")
            missing_details["character_design"] = "è§’è‰²è®¾è®¡"
        if not self.collected_info.get("world_setting"):
            missing_fields.append("world_setting")
            missing_details["world_setting"] = "ä¸–ç•ŒèƒŒæ™¯"
        
        completion_rate = 1.0 - len(missing_fields) / 3
        return {
            "stage": "gamestyle_info",
            "missing_fields": missing_fields,
            "missing_details": missing_details,
            "completion_rate": completion_rate
        }

    def _check_scene_info_gaps(self) -> Dict:
        """æ£€æŸ¥æƒ…èŠ‚ä¿¡æ¯ç¼ºå¤±"""
        missing_fields = []
        missing_details = {}
        
        if not self.collected_info.get("plot_requirements"):
            missing_fields.append("plot_requirements")
            missing_details["plot_requirements"] = "æƒ…èŠ‚éœ€æ±‚"
        if not self.collected_info.get("interaction_requirements"):
            missing_fields.append("interaction_requirements")
            missing_details["interaction_requirements"] = "äº’åŠ¨æ–¹å¼"
        
        completion_rate = 1.0 - len(missing_fields) / 2
        return {
            "stage": "scene_info",
            "missing_fields": missing_fields,
            "missing_details": missing_details,
            "completion_rate": completion_rate
        }
    
    async def generate_response_with_lacked_info(self, lacked_info: Dict) -> str:
        """åŸºäºŽç¼ºå¤±ä¿¡æ¯ç”Ÿæˆå›žå¤"""
        # èŽ·å–åŠ¨æ€prompt
        dynamic_prompt = self.prompts.generate_dynamic_prompt(
            lacked_info["stage"],
            self.collected_info,
            lacked_info
        )
        print(f"dynamic prompt is : {dynamic_prompt}")
        
        # åˆ›å»ºå¯¹è¯é“¾
        conversation = ConversationChain(
            llm=self.llm,
            memory=self.memory,
            prompt=dynamic_prompt
        )
        
        # ç”Ÿæˆå›žå¤ï¼ˆç©ºè¾“å…¥ï¼Œè®©æ¨¡æ¿å¤„ç†ï¼‰
        response = await conversation.apredict(input="")
        return response.strip()
    
    def save_final_requirements(self) -> Dict:
        """ä¿å­˜æœ€ç»ˆæ”¶é›†çš„éœ€æ±‚ä¿¡æ¯åˆ°æ•°æ®åº“"""
        try:
            # æ£€æŸ¥æ•°æ®åº“è¿žæŽ¥
            if not self.db_client:
                return {
                    "success": False,
                    "message": "æ•°æ®åº“æœªè¿žæŽ¥ï¼Œæ— æ³•ä¿å­˜",
                    "timestamp": datetime.now().isoformat()
                }
            
            # ç”Ÿæˆå”¯ä¸€ID
            timestamp = datetime.now().isoformat()
            content_hash = hashlib.md5(json.dumps(self.collected_info, sort_keys=True).encode()).hexdigest()[:8]
            requirement_id = f"requirement_{timestamp}_{content_hash}"
            
            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            requirement_data = {
                "id": requirement_id,
                "user_id": "default_user",  # ç®€åŒ–ä¸ºdefault
                "timestamp": timestamp,
                "collected_info": self.collected_info,
                "final_requirements": self.collected_info,  # ä¸ºäº†å…¼å®¹æ€§
                "status": "completed"
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            save_success = self.db_client.save_requirement(requirement_data)
            
            if save_success:
                return {
                    "success": True,
                    "requirement_id": requirement_id,
                    "message": "éœ€æ±‚ä¿¡æ¯å·²æˆåŠŸä¿å­˜",
                    "timestamp": timestamp
                }
            else:
                return {
                    "success": False,
                    "message": "ä¿å­˜å¤±è´¥",
                    "timestamp": timestamp
                }
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜éœ€æ±‚ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"ä¿å­˜å¤±è´¥: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
    
    def _build_reasoning_graph(self) -> StateGraph:
        """æž„å»ºæŽ¨ç†çŠ¶æ€å›¾"""
        
        workflow = StateGraph(ReasoningState)
        
        # ==================== èŠ‚ç‚¹å®šä¹‰ ====================
        
        # æ–°æµç¨‹ï¼šStage1é›†æˆçš„èŠ‚ç‚¹
        workflow.add_node("check_info_completed", self._check_info_completed)
        workflow.add_node("extract_and_update_info", self._extract_and_update_info)
        workflow.add_node("determine_stage", self._determine_stage)
        workflow.add_node("generate_lack_response", self._generate_lack_response)
        
        # ä¿ç•™ï¼šåŽç»­è¯¦ç»†åº¦å’Œé€‚å®œæ€§æ£€æŸ¥èŠ‚ç‚¹
        workflow.add_node("need_more_details", self._assess_sufficiency)
        workflow.add_node("generate_need_more_details_response", self._generate_sufficiency_questions)
        workflow.add_node("check_fitness", self._check_fitness)
        workflow.add_node("generate_negotiate_response", self._generate_negotiate_response)
        workflow.add_node("generate_finish_response", self._generate_finish_response)
        
        # ==================== æµç¨‹è·¯ç”± ====================
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("check_info_completed")
        
        # æ–°æµç¨‹ï¼šæ€»æ˜¯æµè½¬åˆ°ä¿¡æ¯æå–
        workflow.add_edge("check_info_completed", "extract_and_update_info")
        
        # ä¿¡æ¯æå–åŽæµè½¬åˆ°é˜¶æ®µåˆ¤æ–­
        workflow.add_edge("extract_and_update_info", "determine_stage")
        
        # é˜¶æ®µåˆ¤æ–­åŽçš„æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "determine_stage",
            self._decide_stage_routing,
            {
                "info_incomplete": "generate_lack_response",
                "info_complete": "need_more_details"  # ç»§ç»­åŽŸæœ‰æµç¨‹
            }
        )
        
        # ä¿¡æ¯ä¸è¶³æ—¶ç»“æŸï¼ˆç­‰å¾…ç”¨æˆ·è¡¥å……ï¼‰
        workflow.add_edge("generate_lack_response", END)
        
        # é˜¶æ®µ2è·¯ç”±ï¼šæ£€æŸ¥è¯¦ç»†åº¦å……è¶³æ€§
        workflow.add_conditional_edges(
            "need_more_details",
            self._decide_after_sufficiency_check,
            {
                "need_more_details": "generate_need_more_details_response",
                "sufficiency_passed": "check_fitness"
            }
        )
        
        # éœ€è¦æ›´å¤šç»†èŠ‚æ—¶ï¼Œç”Ÿæˆé—®é¢˜åŽç»“æŸï¼ˆç­‰å¾…ç”¨æˆ·å›žç­”ï¼‰
        workflow.add_edge("generate_need_more_details_response", END)
        
        # é˜¶æ®µ3è·¯ç”±ï¼šæ£€æŸ¥é€‚å®œæ€§
        workflow.add_conditional_edges(
            "check_fitness",
            self._decide_after_fitness_check,
            {
                "fitness_concerns": "generate_negotiate_response",
                "fitness_passed": "generate_finish_response"
            }
        )
        
        # æœ‰é€‚å®œæ€§é—®é¢˜æ—¶ï¼Œç”Ÿæˆåå•†å›žå¤åŽç»“æŸï¼ˆç­‰å¾…ç”¨æˆ·å›žåº”ï¼‰
        workflow.add_edge("generate_negotiate_response", END)
        
        # æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œç”Ÿæˆå®Œæˆå›žå¤åŽç»“æŸ
        workflow.add_edge("generate_finish_response", END)
        
        # ç¼–è¯‘å›¾
        return workflow.compile()
    
    # ==================== å†³ç­–é€»è¾‘ ====================
    
    def _decide_after_sufficiency_check(self, state: ReasoningState) -> str:
        """sufficiencyæ£€æŸ¥åŽçš„è·¯ç”±å†³ç­–"""
        if state.get("sufficiency_passed", False):
            print("âœ… è¯¦ç»†åº¦æ£€æŸ¥é€šè¿‡ï¼Œè¿›å…¥é€‚å®œæ€§æ£€æŸ¥")
            return "sufficiency_passed"
        else:
            print("âŒ è¯¦ç»†åº¦ä¸è¶³ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯")
            return "need_more_details"
    
    def _decide_after_fitness_check(self, state: ReasoningState) -> str:
        """fitnessæ£€æŸ¥åŽçš„è·¯ç”±å†³ç­–"""
        fitness_concerns = state.get("fitness_concerns", [])
        
        if fitness_concerns:
            print(f"âš ï¸ å‘çŽ°é€‚å®œæ€§é—®é¢˜: {len(fitness_concerns)}ä¸ª")
            return "fitness_concerns"
        else:
            print("âœ… é€‚å®œæ€§æ£€æŸ¥é€šè¿‡ï¼Œå‡†å¤‡å®Œæˆ")
            return "fitness_passed"
    
    # ==================== æ–°å¢žèŠ‚ç‚¹å‡½æ•° ====================
    
    async def _extract_and_update_info(self, state: ReasoningState) -> ReasoningState:
        """æå–å¹¶æ›´æ–°ç”¨æˆ·è¾“å…¥çš„ä¿¡æ¯"""
        try:
            # èŽ·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
            messages = state.get("messages", [])
            if not messages:
                return state
                
            latest_message = messages[-1]
            if latest_message.get("role") != "user":
                return state
                
            user_input = latest_message.get("content", "")
            current_stage = state.get("current_stage", "basic_info")
            
            # æå–ä¿¡æ¯
            extracted_info = await self.extract_info(user_input, current_stage)
            print(f"DEBUG: æå–åˆ°çš„ä¿¡æ¯: {extracted_info}")
            
            # æ›´æ–°çŠ¶æ€
            self.update_state(extracted_info)
            
            # æ›´æ–°stateä¸­çš„ä¿¡æ¯
            state["extracted_info"] = extracted_info
            state["collected_info"] = self.collected_info.copy()
            
            return state
            
        except Exception as e:
            print(f"âŒ ä¿¡æ¯æå–å¤±è´¥: {e}")
            return state
    
    async def _determine_stage(self, state: ReasoningState) -> ReasoningState:
        """ç¡®å®šå½“å‰é˜¶æ®µå’Œå®ŒæˆçŠ¶æ€"""
        try:
            # ç¡®å®šå½“å‰é˜¶æ®µ
            current_stage = self.determine_current_stage()
            stage1_complete = self.check_stage_completion()
            
            print(f"DEBUG: å½“å‰é˜¶æ®µ: {current_stage}, Stage1å®Œæˆ: {stage1_complete}")
            
            # æ›´æ–°çŠ¶æ€
            state["current_stage"] = current_stage
            state["stage1_complete"] = stage1_complete
            
            # å¦‚æžœå®Œæˆï¼Œè®¾ç½®ready_for_generationå’Œä¿å­˜éœ€æ±‚
            if stage1_complete:
                save_result = self.save_final_requirements()
                if save_result["success"]:
                    state["ready_for_generation"] = True
                    state["final_requirements"] = self.collected_info.copy()
                    print(f"âœ… éœ€æ±‚ä¿¡æ¯å·²ä¿å­˜: {save_result['requirement_id']}")
            
            return state
            
        except Exception as e:
            print(f"âŒ é˜¶æ®µåˆ¤æ–­å¤±è´¥: {e}")
            return state
    
    def _decide_stage_routing(self, state: ReasoningState) -> str:
        """å†³å®šé˜¶æ®µè·¯ç”±ï¼šå®Œæˆæˆ–æœªå®Œæˆ"""
        stage1_complete = state.get("stage1_complete", False)
        
        if stage1_complete:
            return "info_complete"
        else:
            return "info_incomplete"
    
    # ==================== èŠ‚ç‚¹å®žçŽ° ====================
    
    async def _check_info_completed(self, state: ReasoningState) -> ReasoningState:
        """æ£€æŸ¥åŸºç¡€ä¿¡æ¯å®Œæ•´æ€§ - ç®€åŒ–ç‰ˆï¼Œä¸»è¦ç”¨äºŽåˆå§‹åŒ–"""
        print("ðŸ” æ£€æŸ¥åŸºç¡€ä¿¡æ¯å®Œæ•´æ€§...")
        
        # åŒæ­¥çŠ¶æ€
        self.collected_info = state["collected_info"]
        
        # è¿™ä¸ªèŠ‚ç‚¹çŽ°åœ¨ä¸»è¦æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œå®žé™…æ£€æŸ¥åœ¨determine_stageä¸­è¿›è¡Œ
        print(f"å½“å‰collected_info: {self.collected_info}")
            
        return state
    
    async def _generate_lack_response(self, state: ReasoningState) -> ReasoningState:
        """ç”Ÿæˆä¿¡æ¯ä¸è¶³çš„å›žå¤ - ä½¿ç”¨åˆå¹¶çš„Stage1é€»è¾‘"""
        print("ðŸ“ ç”Ÿæˆä¿¡æ¯ä¸è¶³å›žå¤...")
        print(f"current collected_info is {self.collected_info}")
        
        # åŒæ­¥çŠ¶æ€
        self.collected_info = state["collected_info"]
        
        # èŽ·å–ç¼ºå¤±ä¿¡æ¯è¯¦æƒ…
        lacked_info = self.get_lacked_info()
        
        # ç”Ÿæˆå›žå¤
        response = await self.generate_response_with_lacked_info(lacked_info)
        
        # æ›´æ–°çŠ¶æ€
        state["messages"].append({
            "role": "assistant", 
            "content": response,
            "stage": lacked_info["stage"],
            "lacked_info": lacked_info,
            "timestamp": datetime.now().isoformat()
        })
        
        return state
    
    async def _assess_sufficiency(self, state: ReasoningState) -> ReasoningState:
        """è¯„ä¼°ä¿¡æ¯è¯¦ç»†åº¦å……è¶³æ€§"""
        print("ðŸ” è¯„ä¼°ä¿¡æ¯è¯¦ç»†åº¦...")
        
        collected_info = state["collected_info"]
        conversation_context = self._build_conversation_context(state["messages"])
        
        # ä½¿ç”¨LLMè¯„ä¼°å„ä¸ªç»´åº¦çš„è¯¦ç»†åº¦
        sufficiency_assessment = await self._llm_assess_sufficiency(collected_info, conversation_context)
        
        # æ›´æ–°çŠ¶æ€
        state["sufficiency_score"] = sufficiency_assessment["dimension_scores"]
        state["overall_sufficiency"] = sufficiency_assessment["overall_score"]
        state["sufficiency_passed"] = sufficiency_assessment["overall_score"] >= state["sufficiency_threshold"]
        
        print(f"ðŸ“Š è¯¦ç»†åº¦è¯„ä¼°å®Œæˆ:")
        for dimension, score in sufficiency_assessment["dimension_scores"].items():
            print(f"  {dimension}: {score:.1f}/100")
        print(f"  æ€»ä½“è¯„åˆ†: {sufficiency_assessment['overall_score']:.1f}/100 (é˜ˆå€¼: {state['sufficiency_threshold']})")
        
        return state
        
    async def _generate_sufficiency_questions(self, state: ReasoningState) -> ReasoningState:
        """ç”Ÿæˆè¯¦ç»†åº¦è¡¥å……é—®é¢˜"""
        print("â“ ç”Ÿæˆè¯¦ç»†åº¦è¡¥å……é—®é¢˜...")
        
        # èŽ·å–è¯„ä¼°ç»“æžœ
        sufficiency_scores = state["sufficiency_score"]
        overall_score = state["overall_sufficiency"]
        
        # ç”Ÿæˆé’ˆå¯¹æ€§çš„è¡¥å……é—®é¢˜
        questions_response = await self._llm_generate_sufficiency_questions(
            collected_info=state["collected_info"],
            sufficiency_scores=sufficiency_scores,
            overall_score=overall_score,
            conversation_context=self._build_conversation_context(state["messages"])
        )
        
        # æ›´æ–°çŠ¶æ€
        state["messages"].append({
            "role": "assistant",
            "content": questions_response,
            "type": "sufficiency_questions",
            "sufficiency_scores": sufficiency_scores
        })
        
        return state
        
    async def _check_fitness(self, state: ReasoningState) -> ReasoningState:
        """æ£€æŸ¥å†…å®¹é€‚å®œæ€§"""
        print("ðŸ›¡ï¸ æ£€æŸ¥å†…å®¹é€‚å®œæ€§...")
        
        # èŽ·å–æ”¶é›†çš„ä¿¡æ¯
        collected_info = state["collected_info"]
        conversation_context = self._build_conversation_context(state["messages"])
        
        # ä½¿ç”¨LLMè¿›è¡Œé€‚å®œæ€§æ£€æŸ¥
        fitness_result = await self._llm_check_fitness(collected_info, conversation_context)
        
        # æ›´æ–°çŠ¶æ€
        state["fitness_assessment"] = fitness_result
        state["fitness_concerns"] = fitness_result.get("concerns", [])
        state["fitness_passed"] = len(fitness_result.get("concerns", [])) == 0
        
        if state["fitness_passed"]:
            print("âœ… é€‚å®œæ€§æ£€æŸ¥é€šè¿‡")
        else:
            concern_count = len(state["fitness_concerns"])
            print(f"âš ï¸ å‘çŽ°{concern_count}ä¸ªé€‚å®œæ€§é—®é¢˜éœ€è¦å¤„ç†")
        
        return state
        
    async def _generate_negotiate_response(self, state: ReasoningState) -> ReasoningState:
        """ç”Ÿæˆé€‚å®œæ€§åå•†å›žå¤"""
        print("ðŸ¤ ç”Ÿæˆé€‚å®œæ€§åå•†å›žå¤...")
        
        # èŽ·å–é€‚å®œæ€§æ£€æŸ¥ç»“æžœ
        fitness_assessment = state["fitness_assessment"]
        fitness_concerns = state["fitness_concerns"]
        
        # ç”Ÿæˆåå•†å›žå¤
        negotiate_response = await self._llm_generate_negotiate_response(
            fitness_concerns=fitness_concerns,
            collected_info=state["collected_info"],
            conversation_context=self._build_conversation_context(state["messages"])
        )
        
        # æ›´æ–°çŠ¶æ€
        state["messages"].append({
            "role": "assistant",
            "content": negotiate_response,
            "type": "fitness_negotiation",
            "fitness_concerns": fitness_concerns
        })
        
        return state
        
    async def _generate_finish_response(self, state: ReasoningState) -> ReasoningState:
        """ç”Ÿæˆæœ€ç»ˆå®Œæˆå›žå¤"""
        print("ðŸŽ‰ ç”Ÿæˆæœ€ç»ˆå®Œæˆå›žå¤...")
        
        # ç”Ÿæˆæœ€ç»ˆç¡®è®¤å›žå¤
        final_response = await self._llm_generate_final_response(
            collected_info=state["collected_info"],
            conversation_context=self._build_conversation_context(state["messages"])
        )
        
        # æ ‡è®°ä¸ºready_for_generation
        state["ready_for_generation"] = True
        state["final_requirements"] = state["collected_info"].copy()
        
        # æ›´æ–°çŠ¶æ€
        state["messages"].append({
            "role": "assistant",
            "content": final_response,
            "type": "completion_confirmation"
        })
        
        return state
    
    # ==================== LLMè¾…åŠ©æ–¹æ³• ====================
    
    def _build_conversation_context(self, messages: List[Dict[str, str]]) -> str:
        """æž„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        if not messages:
            return "æš‚æ— å¯¹è¯è®°å½•"
            
        context_parts = []
        # å–æœ€è¿‘10è½®å¯¹è¯
        recent_messages = messages[-10:] if len(messages) > 10 else messages
        
        for msg in recent_messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")  # ç§»é™¤é•¿åº¦é™åˆ¶
            context_parts.append(f"{role}: {content}")
            
        return "\n".join(context_parts)
    
    async def _llm_assess_sufficiency(self, collected_info: Dict[str, Any], 
                                    conversation_context: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¯„ä¼°ä¿¡æ¯è¯¦ç»†åº¦å……è¶³æ€§"""
        
        # ä½¿ç”¨PromptTemplate
        prompt_template = self.prompts.get_sufficiency_assessment_prompt()
        assessment_prompt = prompt_template.format(
            collected_info=self._format_collected_info_for_assessment(collected_info),
            conversation_context=conversation_context
        )

        try:
            response = await self.llm.apredict(assessment_prompt)
            # æå–markdownä»£ç å—ä¸­çš„JSONå†…å®¹
            json_content = self._extract_json_from_markdown(response.strip())
            result = json.loads(json_content)
            return result
        except Exception as e:
            print(f"âŒ LLMè¯„ä¼°å¤±è´¥: {e}")
            # è¿”å›žé»˜è®¤çš„ä½Žåˆ†è¯„ä¼°
            return {
                "dimension_scores": {
                    "åŸºç¡€ä¿¡æ¯å……è¶³æ€§": 60,
                    "æ•™å­¦ä¿¡æ¯å……è¶³æ€§": 60,
                    "æ¸¸æˆè®¾å®šå……è¶³æ€§": 60,
                    "æƒ…èŠ‚è®¾å®šå……è¶³æ€§": 60
                },
                "overall_score": 60,
                "detailed_feedback": {
                    "strengths": [],
                    "weaknesses": ["è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯"],
                    "suggestions": ["è¯·é‡æ–°è¯„ä¼°ä¿¡æ¯è¯¦ç»†åº¦"]
                }
            }
    
    async def _llm_generate_sufficiency_questions(self, collected_info: Dict[str, Any], 
                                                sufficiency_scores: Dict[str, float], 
                                                overall_score: float,
                                                conversation_context: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆè¯¦ç»†åº¦è¡¥å……é—®é¢˜"""
        
        # æ‰¾åˆ°å¾—åˆ†æœ€ä½Žçš„ç»´åº¦
        lowest_dimension = min(sufficiency_scores.keys(), key=lambda k: sufficiency_scores[k])
        lowest_score = sufficiency_scores[lowest_dimension]
        
        # ä½¿ç”¨PromptTemplate
        prompt_template = self.prompts.get_sufficiency_questions_prompt()
        questions_prompt = prompt_template.format(
            collected_info=self._format_collected_info_for_assessment(collected_info),
            overall_score=overall_score,
            lowest_dimension=lowest_dimension,
            lowest_score=lowest_score,
            conversation_context=conversation_context
        )

        try:
            return await self.llm.apredict(questions_prompt)
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè¡¥å……é—®é¢˜å¤±è´¥: {e}")
            return f"ä¸ºäº†æ›´å¥½åœ°è®¾è®¡æ¸¸æˆï¼Œè¯·æä¾›æ›´å¤šå…³äºŽ{lowest_dimension}çš„è¯¦ç»†ä¿¡æ¯ã€‚æ¯”å¦‚æ‚¨å¸Œæœ›æ¸¸æˆå…·ä½“å¦‚ä½•å¸®åŠ©å­¦ç”Ÿå­¦ä¹ ï¼Ÿ"
    
    async def _llm_check_fitness(self, collected_info: Dict[str, Any], 
                               conversation_context: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMæ£€æŸ¥å†…å®¹é€‚å®œæ€§"""
        
        # ä½¿ç”¨PromptTemplate
        prompt_template = self.prompts.get_fitness_check_prompt()
        fitness_prompt = prompt_template.format(
            collected_info=self._format_collected_info_for_assessment(collected_info),
            conversation_context=conversation_context
        )

        try:
            response = await self.llm.apredict(fitness_prompt)
            json_content = self._extract_json_from_markdown(response.strip())
            return json.loads(json_content)
        except Exception as e:
            print(f"âŒ é€‚å®œæ€§æ£€æŸ¥å¤±è´¥: {e}")
            # è¿”å›žé»˜è®¤é€šè¿‡çš„ç»“æžœ
            return {
                "overall_fitness": "é€‚å®œ",
                "concerns": [],
                "positive_aspects": ["å†…å®¹ç§¯æžå¥åº·"]
            }
    
    async def _llm_generate_negotiate_response(self, fitness_concerns: List[Dict], 
                                             collected_info: Dict[str, Any],
                                             conversation_context: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆé€‚å®œæ€§åå•†å›žå¤"""

        concerns_text = "\n".join([
            f"- {concern.get('category', concern.get('type', 'æœªçŸ¥ç±»åˆ«'))}: {concern.get('description', 'æœªçŸ¥æè¿°')} (ä¸¥é‡ç¨‹åº¦: {concern.get('severity', 'æœªçŸ¥')})"
            for concern in fitness_concerns
        ])
        
        # ä½¿ç”¨PromptTemplate
        prompt_template = self.prompts.get_negotiate_response_prompt()
        negotiate_prompt = prompt_template.format(
            concerns_text=concerns_text,
            collected_info=self._format_collected_info_for_assessment(collected_info),
            conversation_context=conversation_context
        )

        try:
            return await self.llm.apredict(negotiate_prompt)
        except Exception as e:
            print(f"âŒ ç”Ÿæˆåå•†å›žå¤å¤±è´¥: {e}")
            return "å‘çŽ°ä¸€äº›éœ€è¦è°ƒæ•´çš„åœ°æ–¹ï¼Œè¯·ä¿®æ”¹è®¾è®¡ä»¥ç¡®ä¿å†…å®¹æ›´é€‚åˆç›®æ ‡å­¦ç”Ÿç¾¤ä½“ã€‚"
    
    async def _llm_generate_final_response(self, collected_info: Dict[str, Any],
                                         conversation_context: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆç¡®è®¤å›žå¤"""
        
        # ä½¿ç”¨PromptTemplate
        prompt_template = self.prompts.get_finish_response_prompt()
        final_prompt = prompt_template.format(
            collected_info=self._format_collected_info_for_assessment(collected_info),
            conversation_context=conversation_context
        )

        try:
            return await self.llm.apredict(final_prompt)
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæœ€ç»ˆå›žå¤å¤±è´¥: {e}")
            return "ðŸŽ‰ ä¿¡æ¯æ”¶é›†å®Œæˆï¼æ‚¨çš„æ•™è‚²æ¸¸æˆè®¾è®¡éžå¸¸æ£’ï¼Œæˆ‘ä»¬çŽ°åœ¨å¼€å§‹ç”Ÿæˆå…·ä½“çš„æ¸¸æˆå†…å®¹ã€‚"
    
    def _extract_json_from_markdown(self, content: str) -> str:
        """ä»Žmarkdownä»£ç å—ä¸­æå–JSONå†…å®¹"""
        content = content.strip()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«markdownä»£ç å—
        if content.startswith("```json") and content.endswith("```"):
            # æå–ä»£ç å—ä¸­çš„å†…å®¹
            lines = content.split('\n')
            # ç§»é™¤ç¬¬ä¸€è¡Œçš„```jsonå’Œæœ€åŽä¸€è¡Œçš„```
            json_lines = lines[1:-1]
            return '\n'.join(json_lines)
        elif content.startswith("```") and content.endswith("```"):
            # å¤„ç†å…¶ä»–ç±»åž‹çš„ä»£ç å—
            lines = content.split('\n')
            json_lines = lines[1:-1]
            return '\n'.join(json_lines)
        else:
            # å¦‚æžœæ²¡æœ‰ä»£ç å—åŒ…è£…ï¼Œç›´æŽ¥è¿”å›žåŽŸå†…å®¹
            return content

    def _format_collected_info_for_assessment(self, collected_info: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ”¶é›†çš„ä¿¡æ¯ç”¨äºŽè¯„ä¼°"""
        formatted_parts = []
        
        # åŸºç¡€ä¿¡æ¯
        if any([collected_info.get("subject"), collected_info.get("grade"), collected_info.get("knowledge_points")]):
            formatted_parts.append("ã€åŸºç¡€ä¿¡æ¯ã€‘")
            if collected_info.get("subject"):
                formatted_parts.append(f"  å­¦ç§‘: {collected_info['subject']}")
            if collected_info.get("grade"):
                formatted_parts.append(f"  å¹´çº§: {collected_info['grade']}")
            if collected_info.get("knowledge_points"):
                points = collected_info['knowledge_points']
                if isinstance(points, list):
                    points = "ã€".join(points)
                formatted_parts.append(f"  çŸ¥è¯†ç‚¹: {points}")

        # æ•™å­¦ä¿¡æ¯
        if any([collected_info.get("teaching_goals"), collected_info.get("teaching_difficulties")]):
            formatted_parts.append("\nã€æ•™å­¦ä¿¡æ¯ã€‘")
            if collected_info.get("teaching_goals"):
                goals = collected_info['teaching_goals']
                if isinstance(goals, list):
                    goals = "ã€".join(goals)
                formatted_parts.append(f"  æ•™å­¦ç›®æ ‡: {goals}")
            if collected_info.get("teaching_difficulties"):
                difficulties = collected_info['teaching_difficulties']
                if isinstance(difficulties, list):
                    difficulties = "ã€".join(difficulties)
                formatted_parts.append(f"  æ•™å­¦éš¾ç‚¹: {difficulties}")

        # æ¸¸æˆè®¾å®š
        if any([collected_info.get("game_style"), collected_info.get("character_design"),
                collected_info.get("world_setting")]):
            formatted_parts.append("\nã€æ¸¸æˆè®¾å®šã€‘")
            if collected_info.get("game_style"):
                formatted_parts.append(f"  æ¸¸æˆé£Žæ ¼: {collected_info['game_style']}")
            if collected_info.get("character_design"):
                formatted_parts.append(f"  è§’è‰²è®¾è®¡: {collected_info['character_design']}")
            if collected_info.get("world_setting"):
                formatted_parts.append(f"  ä¸–ç•ŒèƒŒæ™¯: {collected_info['world_setting']}")

        # æƒ…èŠ‚è®¾å®š
        if any([collected_info.get("plot_requirements"), collected_info.get("interaction_requirements")]):
            formatted_parts.append("\nã€æƒ…èŠ‚è®¾å®šã€‘")
            if collected_info.get("plot_requirements"):
                plots = collected_info['plot_requirements']
                if isinstance(plots, list):
                    plots = "ã€".join(plots)
                formatted_parts.append(f"  æƒ…èŠ‚éœ€æ±‚: {plots}")
            if collected_info.get("interaction_requirements"):
                interactions = collected_info['interaction_requirements']
                if isinstance(interactions, list):
                    interactions = "ã€".join(interactions)
                formatted_parts.append(f"  äº’åŠ¨æ–¹å¼: {interactions}")

        return "\n".join(formatted_parts) if formatted_parts else "æš‚æ— è¯¦ç»†ä¿¡æ¯"
    # ==================== å…¬å…±æŽ¥å£æ–¹æ³• ====================
    
    def initialize_reasoning_state(self, session_id: str, user_id: str, 
                                 collected_info: Dict[str, Any]) -> ReasoningState:
        """åˆå§‹åŒ–æŽ¨ç†çŠ¶æ€"""
        
        return ReasoningState(
            session_id=session_id,
            messages=[],
            user_id=user_id,
            
            # éœ€æ±‚æ”¶é›†çŠ¶æ€
            collected_info=collected_info,
            stage1_complete=False,
            
            # === Stage1çŠ¶æ€å­—æ®µ ===
            extracted_info={},
            current_stage="basic_info",
            
            # è¯¦ç»†åº¦è¯„ä¼°çŠ¶æ€  
            sufficiency_score={},
            overall_sufficiency=0.0,
            sufficiency_threshold=75.0,  # å¯é…ç½®
            sufficiency_passed=False,
            
            # é€‚å®œæ€§æ£€æŸ¥çŠ¶æ€
            fitness_assessment={},
            fitness_concerns=[],
            fitness_passed=False,
            
            # æœ€ç»ˆçŠ¶æ€
            ready_for_generation=False,
            final_requirements={}
        )
    
    async def process_reasoning_request(self, session_id: str, user_id: str, 
                                      collected_info: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æŽ¨ç†è¯·æ±‚çš„ä¸»å…¥å£"""
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = self.initialize_reasoning_state(session_id, user_id, collected_info)
        
        # è¿è¡Œå›¾
        thread_config = {"configurable": {"thread_id": session_id}}
        
        try:
            final_state = await self.graph.ainvoke(initial_state, config=thread_config)
            
            return {
                "success": True,
                "final_state": final_state,
                "ready_for_generation": final_state.get("ready_for_generation", False),
                "messages": final_state.get("messages", []),
                "stage": self._determine_current_stage(final_state)
            }
            
        except Exception as e:
            print(f"âŒ StateGraphæ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "ready_for_generation": False
            }
    
    async def process_reasoning_request_with_state(self, reasoning_state: Dict[str, Any], 
                                                  user_input: str) -> Dict[str, Any]:
        """ä½¿ç”¨å·²æœ‰çŠ¶æ€å¤„ç†æŽ¨ç†è¯·æ±‚ - æ”¯æŒçŠ¶æ€æŒä¹…åŒ–"""
        
        try:
            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°æ¶ˆæ¯åŽ†å²
            if "messages" not in reasoning_state:
                reasoning_state["messages"] = []
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            reasoning_state["messages"].append({
                "role": "user",
                "content": user_input,
                "timestamp": datetime.now().isoformat()
            })
            
            # åŒæ­¥æ›´æ–°collected_infoçŠ¶æ€
            print(f"DEBUG: åŒæ­¥æ›´æ–°çŠ¶æ€ï¼Œcollected_info: {reasoning_state.get('collected_info', {})}")
            self.collected_info = reasoning_state.get("collected_info", {})
            
            # æ¸…ç©ºä¹‹å‰çš„memoryå¹¶é‡æ–°åŒæ­¥å¯¹è¯åŽ†å²ï¼ˆé¿å…é‡å¤ï¼‰
            self.memory.chat_memory.clear()
            
            # é‡æ–°æ·»åŠ æ‰€æœ‰åŽ†å²æ¶ˆæ¯åˆ°memory
            messages = reasoning_state.get("messages", [])
            for msg in messages:
                if msg.get("role") == "user":
                    self.memory.chat_memory.add_user_message(msg["content"])
                elif msg.get("role") == "assistant":
                    self.memory.chat_memory.add_ai_message(msg["content"])
            
            # è¿è¡Œå›¾
            thread_config = {"configurable": {"thread_id": reasoning_state.get("session_id", "default")}}
            
            final_state = await self.graph.ainvoke(reasoning_state, config=thread_config)
            
            return {
                "success": True,
                "final_state": final_state,
                "ready_for_generation": final_state.get("ready_for_generation", False),
                "messages": final_state.get("messages", []),
                "stage": self._determine_current_stage(final_state)
            }
            
        except Exception as e:
            print(f"âŒ StateGraphæŒä¹…åŒ–æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "ready_for_generation": False
            }
    
    def _determine_current_stage(self, final_state: ReasoningState) -> str:
        """æ ¹æ®æœ€ç»ˆçŠ¶æ€ç¡®å®šå½“å‰æ‰€å¤„é˜¶æ®µ"""
        
        if final_state.get("ready_for_generation"):
            return "ready_for_generation"
        elif not final_state.get("stage1_complete", False):
            return "stage1_collecting"
        elif not final_state.get("sufficiency_passed", False):
            return "need_more_details"
        elif not final_state.get("fitness_passed", False):
            return "fitness_check"
        else:
            return "unknown"


# ä¾¿åˆ©å‡½æ•°
def create_reasoning_graph() -> ReasoningGraph:
    """åˆ›å»ºReasoningGraphå®žä¾‹çš„ä¾¿åˆ©å‡½æ•°"""
    return ReasoningGraph()